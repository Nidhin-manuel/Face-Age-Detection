# -*- coding: utf-8 -*-
"""23032566_Nidhin_Manuel_Face_Age_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-T_A8wGWZCd8PL-W_cZk9ITtWVkGKs3b

### ðŸ“¦ Import Required Libraries
"""

# System and OS
import os
import random

# Image handling
import numpy as np
import pandas as pd
from PIL import Image
from glob import glob

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Deep Learning (TensorFlow/Keras)
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet import preprocess_input
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.models import Sequential
from tensorflow.keras.losses import MeanAbsoluteError
from tensorflow.keras.preprocessing import image
from sklearn.model_selection import train_test_split

# Data handling and splitting
from sklearn.model_selection import train_test_split

# Disable TensorFlow warnings (optional for cleaner logs)
import warnings
warnings.filterwarnings('ignore')

# !pip show tensorflow
# !pip uninstall -y tensorflow
# !pip install tensorflow --upgrade

"""### ðŸ“‚ Mount Google Drive and Setup Dataset Path

We start by mounting Google Drive and defining the dataset folder path using the original project structure.
This ensures consistency with earlier versions and keeps all variable names intact.
"""

# Mount Google Drive to access the uploaded folder
from google.colab import drive
drive.mount('/content/drive')

# Define the main directory path where images are stored
import os

main_folder_path = "/content/drive/My Drive/UTKface_inthewild"

# Check if the main directory exists
if not os.path.exists(main_folder_path):
    print("Error: The folder UTKface_inthewild does not exist in My Drive. Please check the path.")
else:
    print("UTKface_inthewild folder found!")

"""Identify Dataset Subfolders"""

# List all subfolders (part1, part2, part3)
subfolders = [os.path.join(main_folder_path, folder) for folder in os.listdir(main_folder_path) if os.path.isdir(os.path.join(main_folder_path, folder))]

print(f"Found {len(subfolders)} subfolders: {subfolders}")

"""Retrieve All Image File Paths"""

import glob

# Retrieves all image paths
image_files = glob.glob(os.path.join(main_folder_path, "**", "*.jpg"), recursive = True)

print(f"Total images found: {len(image_files)}")

"""#### ðŸ§¹ Filter Valid UTKFace Images Based on Filename Pattern

The UTKFace dataset encodes metadata (age, gender, ethnicity, date) in the image filenames using the format:
age_gender_ethnicity_date.jpg

To ensure only properly labeled images are used, we define a regular expression pattern to validate filenames and filter out any irregular entries or corrupt files.
"""

import re

# Define the valid UTKFace filename pattern
def is_utkface_image(filename):
    # UTKFace pattern: age_gender_race_date.jpg
    return bool(re.match(r"^\d+_\d+_\d+_\d+\.(jpg|jpeg|png)$", filename))

# Apply the function
# Filter images based on the UTKFace naming pattern
utkface_images = [img for img in image_files if is_utkface_image(os.path.basename(img))]
print(f"Valid UTKFace images found: {len(utkface_images)}")

"""Visual Inspection of Random UTKFace Images"""

# Number of random images to display
num_images = 3  # Change this value to display more or fewer images

# Check if there are enough images available
if len(utkface_images) > 0:
    random_images = random.sample(utkface_images, min(num_images, len(utkface_images)))

    # Display the selected images
    fig, axes = plt.subplots(1, len(random_images), figsize=(10, 5))

    if len(random_images) == 1:
        axes = [axes]  # Ensure axes is iterable when only one image is selected

    for ax, image_path in zip(axes, random_images):
        image = Image.open(image_path)
        ax.imshow(image)
        ax.axis("off")  # Hide axis labels
        ax.set_title("Random UTKFace Image")

    plt.show()
else:
    print("No UTKFace images found.")

"""##  ðŸ§¼ PRE-PROCESSING, Dataset Configuration, Label Extraction & Pipeline Setup


We begin by configuring global constants for image size, batch size, and random seed.
We then:

1.   Traverse the dataset directory
2.  Extract age labels from the filenames (formatted as age_gender_ethnicity_date.jpg)
3. Store both file paths and corresponding age values

"""

# -----------------------------
# CONFIG
# -----------------------------
IMG_SIZE = (64, 64)   # Resize all images
BATCH_SIZE = 32       # Number of images in one batch
SEED = 42

# Path to UTKFace dataset folder
dataset_path = "/content/drive/MyDrive/UTKface_inthewild"

# -----------------------------
# LOAD IMAGE PATHS & AGE LABELS
# -----------------------------
image_paths = []
age_labels = []

for root, dirs, files in os.walk(dataset_path):
    for fname in files:
        if fname.endswith('.jpg'):
            try:
                age = int(fname.split("_")[0])  # Extract age from filename
                full_path = os.path.join(root, fname)
                image_paths.append(full_path)
                age_labels.append(age)
            except:
                continue  # Skip corrupted or improperly named files

print(f"Total images with valid labels: {len(image_paths)}")

"""We use train_test_split() to divide the dataset into 80% training and 20% validation sets.

Next, we define a TensorFlow load_and_preprocess() function to:

1. Read the image file
2. Decode the image
3. Resize to (64, 64)
4. Normalize pixel values to the [0, 1] range

and we construct efficient tf.data.Dataset pipelines for training and validation using batching, shuffling, and prefetching to optimize GPU usage.
"""

# -----------------------------
# TRAIN-VALIDATION SPLIT
# -----------------------------

# Split the dataset into Training and Validation Sets
# 80% for training, 20% for validation
train_paths, val_paths, train_ages, val_ages = train_test_split(
    image_paths,  # Full list of image file paths
    age_labels,   # Corresponding list of ages
    test_size = 0.2,  # 20% of data used for validation
    random_state = SEED  # Ensure reproducibility
)

print(f"Training samples: {len(train_paths)}, Validation samples: {len(val_paths)}")


# -----------------------------
# CREATE DATASET PIPELINE
# -----------------------------

def load_and_preprocess(path, label):
    """
    Reads an image from disk, decodes it into a dense tensor, resizes to IMG_SIZE,
    normalizes pixel values to [0,1] range, and returns the processed image with its label.
    """
    image_str = tf.io.read_file(path)
    img = tf.image.decode_jpeg(image_str, channels=3)
    img = tf.image.resize(img, IMG_SIZE)
    img = tf.cast(img, tf.float32) / 255.0
    return img, label

# Training Dataset: (path, label) -> (processed_image, label)
train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_ages))
val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_ages))

# Validation Dataset
train_ds = train_ds.map(load_and_preprocess).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
val_ds = val_ds.map(load_and_preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

"""#### Sample image augmentations (rotation, flip, zoom, translation) applied during preprocessing using ImageDataGenerator"""

# Use a valid sample from your dataset
sample_image_path = utkface_images[0]  # Uses first valid UTKFace image

# Load and prepare the image
img = load_img(sample_image_path, target_size=(64, 64))
x = img_to_array(img)
x = x.reshape((1,) + x.shape)

# Augmentation setup
datagen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True
)

# Generate and display 5 augmented images
fig, axes = plt.subplots(1, 5, figsize=(15, 4))
for i, batch in enumerate(datagen.flow(x, batch_size=1)):
    axes[i].imshow(batch[0].astype("uint8"))
    axes[i].axis("off")
    axes[i].set_title(f"Augmented {i+1}")
    if i == 4:
        break

plt.suptitle("Sample Image Augmentations using ImageDataGenerator", fontsize=16)
plt.tight_layout()
plt.show()

"""## Model 1: ResNet50 Regression Model

we build the first version of our deep learning model using transfer learning with the ResNet50 architecture as a base.
"""

# -----------------------------
# BUILD MODEL
# -----------------------------

# Build the model with ResNet50 base
base_model = ResNet50(weights = 'imagenet', include_top = False, input_shape = (64, 64, 3))
base_model.trainable = False  # Freeze base model

# Add custom regression head
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dropout(0.3),
    Dense(128, activation='relu'),
    Dropout(0.2),
    Dense(1, activation = 'linear')  # Regression output
])

# Compile the model
model.compile(
    optimizer = Adam(learning_rate = 0.0005),
    loss=MeanAbsoluteError(),
    metrics = ['mae']
)

# -----------------------------
# TRAIN MODEL
# -----------------------------

# Add callbacks
early_stop = EarlyStopping(patience = 5, restore_best_weights = True)
checkpoint = ModelCheckpoint("best_model_resnet_age.h5", save_best_only = True)

# Train the model
history = model.fit(
    train_ds,
    validation_data = val_ds,
    epochs = 20,
    callbacks=[early_stop, checkpoint]
)

"""### ðŸ“ˆ Visualize Model Performance and Evaluate on Validation Set

After training, we evaluate the models performance both numerically and visually to assess convergence and check for overfitting
"""

# Plot training and validation MAE over epochs
def plot_training_history(history):
    plt.figure(figsize=(10, 5))
    plt.plot(history.history['mae'], label='Train MAE')
    plt.plot(history.history['val_mae'], label='Val MAE')
    plt.title("Model Performance (MAE) Over Epochs")
    plt.xlabel("Epoch")
    plt.ylabel("Mean Absolute Error")
    plt.legend()
    plt.grid(True)
    plt.show()

plot_training_history(history)

# Evaluate model on validation dataset
val_loss, val_mae = model.evaluate(val_ds)
print(f"\n Final Validation MAE: {val_mae:.2f} years")

"""### Prediction & Visualization

To assess how well the model generalizes on unseen data, we randomly sample images from the validation set and compare the actual age labels with the models predicted values.
"""

# Convert validation set to list (for indexing)
val_images = list(val_ds.unbatch().as_numpy_iterator())

# Pick N random samples to visualize
import random
num_samples = 8
samples = random.sample(val_images, num_samples)


# Plot predictions with improved layout
plt.figure(figsize=(16, 10))


for i, (img, actual_age) in enumerate(samples):
    # Predict age
    img_input = tf.expand_dims(img, axis=0)
    predicted_age = model.predict(img_input, verbose=0)[0][0]

    # Upscale image for display only (128x128) and convert to uint8
    upscaled_img = tf.image.resize(img, (128, 128)).numpy()
    upscaled_img = (upscaled_img * 255).astype("uint8")

    # Plot
    plt.subplot(2, 4, i+1)
    plt.imshow(upscaled_img)
    plt.axis('off')
    plt.title(f"Actual: {int(actual_age)}\nPredicted: {int(predicted_age)}", fontsize=14, pad=10)

plt.suptitle("Face Age Prediction: Actual vs. Predicted", fontsize=18, y=1.02)
plt.subplots_adjust(wspace=0.3, hspace=0.4)
plt.tight_layout()
plt.show()

# Save this plot to file
# plt.savefig("age_predictions_grid.png", dpi=300, bbox_inches='tight')

"""## **Model 2:** Fine-Tuned Model (Supervised Learning)

### Fine-Tune by Unfreezing Part of the ResNet50 Model

After training the top custom layers on frozen ResNet50 features, we now fine-tune the model by unfreezing some of the deeper layers.
"""

#  Unfreeze Layers from ResNet50

# Unfreeze the base model
base_model.trainable = True

# Optional: Freeze some early layers to avoid overfitting
for layer in base_model.layers[:100]:
    layer.trainable = False

print(f"Total trainable layers after unfreezing: {sum([layer.trainable for layer in base_model.layers])}")

""" #### Fine-Tuning the ResNet50 Model by Lowering the Learning Rate"""

# Compile with Lower Learning Rate

from tensorflow.keras.optimizers import Adam

# Recompile with a lower learning rate for fine-tuning
model.compile(
    optimizer=Adam(learning_rate=1e-5),  # Smaller LR to avoid destroying pre-trained weights
    loss='mae',
    metrics=['mae']
)

""" Training Configuration"""

# Train the Model Again

# Fine-tune the model
fine_tune_history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=10,  # Fewer epochs to start with
    callbacks=[early_stop, checkpoint]
)

# Plot fine-tuning training history
plot_training_history(fine_tune_history)

# Save Your Model for Deployment
model.save("/content/fine_tuned_age_model.h5")

"""### Predict Again and Visualize Results

To qualitatively assess the fine-tuned model, we sampled 8 random images from the validation set and compared actual vs. predicted ages.
"""

# Pick 8 fresh samples from validation set
val_images = list(val_ds.unbatch().as_numpy_iterator())
samples = random.sample(val_images, 8)

# Plot predictions
plt.figure(figsize=(16, 10))
for i, (img, actual_age) in enumerate(samples):
    # Predict
    img_input = tf.expand_dims(img, axis=0)
    predicted_age = model.predict(img_input, verbose=0)[0][0]

    # Upscale for display
    upscaled_img = tf.image.resize(img, (128, 128)).numpy()
    upscaled_img = (upscaled_img * 255).astype("uint8")

    # Display
    plt.subplot(2, 4, i+1)
    plt.imshow(upscaled_img)
    plt.axis('off')
    plt.title(f"Actual: {int(actual_age)}\nPredicted: {int(predicted_age)}", fontsize=14, pad=10)

plt.suptitle("Fine-Tuned Model â€“ Actual vs. Predicted Age", fontsize=18, y=1.02)
plt.subplots_adjust(wspace=0.3, hspace=0.4)
plt.tight_layout()
plt.show()

"""### Saving the Model for Submission or Reuse"""

# Save fine-tuned model as HDF5 format
model.save("/content/fine_tuned_age_model.h5")

"""## **Model 3:** Semi-supervised Learning

### Generate Pseudo-Labels Using Trained Model

To explore the potential of semi-supervised learning, we implemented a pseudo-labeling approach. Pseudo-labeling involves using a pre-trained model to generate predictions on unlabeled or validation data, and then incorporating these "pseudo-labeled" examples into the training process.
"""

pseudo_images = val_images[:500]  # Example: take 500 "unlabeled" images

pseudo_X = []
pseudo_y = []

for img, _ in pseudo_images:
    pred = model.predict(tf.expand_dims(img, axis=0), verbose=0)[0][0]
    pseudo_X.append(img)
    pseudo_y.append(pred)  # Use model's prediction as label

print(f"Generated {len(pseudo_y)} pseudo-labels.")

"""### Combining Labeled and Pseudo-Labeled Data

To train the model in a semi-supervised fashion, we merged two subsets:

1. Real labeled data from the original training set (500 samples)

2. Pseudo-labeled data generated from the validation set (500 samples)

This approach helps the model generalize better by leveraging both human-annotated and machine-inferred data.
"""

# Convert train_ds to numpy arrays for combining
real_X = []
real_y = []
for img, label in train_ds.unbatch().take(500):  # You can use full or partial
    real_X.append(img)
    real_y.append(label)

# Combine both
combined_X = tf.convert_to_tensor(real_X + pseudo_X)
combined_y = tf.convert_to_tensor(real_y + pseudo_y)

# Shuffle & create new dataset
combined_ds = tf.data.Dataset.from_tensor_slices((combined_X, combined_y))
combined_ds = combined_ds.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

"""### Retrain the Model with Combined Dataset"""

# Optionally recompile with a lower LR
model.compile(
    optimizer=Adam(learning_rate=1e-5),
    loss='mae',
    metrics=['mae']
)

# Train again
pseudo_history = model.fit(
    combined_ds,
    validation_data=val_ds,
    epochs=5,
    callbacks=[early_stop]
)

# Use some validation data for predictions
val_images = list(val_ds.unbatch().as_numpy_iterator())
samples = random.sample(val_images, 8)

plt.figure(figsize=(16, 10))
for i, (img, actual_age) in enumerate(samples):
    # Predict
    img_input = tf.expand_dims(img, axis=0)
    predicted_age = model.predict(img_input, verbose=0)[0][0]

    # Upscale for display
    upscaled_img = tf.image.resize(img, (128, 128)).numpy()
    upscaled_img = (upscaled_img * 255).astype("uint8")

    # Plot
    plt.subplot(2, 4, i + 1)
    plt.imshow(upscaled_img)
    plt.axis('off')
    plt.title(f"Actual: {int(actual_age)}\nPredicted: {int(predicted_age)}", fontsize=14, pad=10)

plt.suptitle("Semi-Supervised Model â€“ Actual vs. Predicted Age", fontsize=18, y=1.02)
plt.subplots_adjust(wspace=0.3, hspace=0.4)
plt.tight_layout()
plt.show()

""" #### Semi-Supervised Training History"""

# Plot training and validation MAE for Semi-Supervised Learning
def plot_semi_supervised_history(pseudo_history):
    plt.figure(figsize=(10, 5))
    plt.plot(pseudo_history.history['mae'], label='Train MAE')
    plt.plot(pseudo_history.history['val_mae'], label='Val MAE')
    plt.title("Semi-Supervised Model Performance Over Epochs")
    plt.xlabel("Epoch")
    plt.ylabel("Mean Absolute Error")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Call the function
plot_semi_supervised_history(pseudo_history)

"""### Performance Comparison Table"""

from matplotlib.backends.backend_pdf import PdfPages

# Performance comparison data
data = [
    ["Model Phase", "Description", "Validation MAE (Years)"],
    ["Baseline", "Frozen ResNet50 + Regression Head", "14.87"],
    ["Fine-Tuned", "Top 50 layers unfrozen, low LR", "13.71"],
    ["Semi-Supervised", "+500 pseudo-labeled samples", "14.15"]
]

# Create a PDF file with the table
with PdfPages("/content/performance_comparison_table.pdf") as pdf:
    fig, ax = plt.subplots(figsize=(10, 2))
    ax.axis('tight')
    ax.axis('off')
    table = ax.table(cellText=data, colLabels=None, cellLoc='center', loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(12)
    table.scale(1.2, 2.0)
    pdf.savefig(fig, bbox_inches='tight')
    plt.close()

from google.colab import files
files.download("/content/performance_comparison_table.pdf")


print("Performance comparison table saved as PDF: performance_comparison_table.pdf")

"""## Loss Curve Visualization (Training vs Validation MAE)

#### Model Training - MAE Comparison

The plot below compares the Mean Absolute Error (MAE) across training epochs for three model phases:
- **Baseline Model**: ResNet50 with frozen layers
- **Fine-Tuned Model**: Top layers unfrozen with a low learning rate
- **Semi-Supervised Model**: Enhanced with 500 pseudo-labeled samples

This visualization highlights the performance improvements through fine-tuning and the effects of incorporating pseudo-labeled data. The fine-tuned model shows the best validation MAE, while the semi-supervised model significantly reduces training MAE, reflecting strong internal learning.
"""

# Example (update with your real `history` and `fine_tune_history` objects)
def plot_mae(history, label):
    plt.plot(history.history['mae'], label=f'{label} Train MAE')
    plt.plot(history.history['val_mae'], label=f'{label} Val MAE')

plt.figure(figsize=(10, 5))
plot_mae(history, "Baseline")
plot_mae(fine_tune_history, "Fine-Tune")
if 'pseudo_history' in locals():
    plot_mae(pseudo_history, "Semi-Supervised")

plt.title("Model Training - MAE Comparison")
plt.xlabel("Epochs")
plt.ylabel("Mean Absolute Error (Years)")
plt.legend()
plt.grid(True)
plt.show()

"""#### Age Distribution Histogram

The histogram below illustrates the distribution of age labels in the UTKFace dataset. The dataset spans a wide range of ages from infants to elderly individuals, making it suitable for training age regression models.

Visualizing the dataset helps identify class imbalance â€” a common challenge in real-world datasets. This insight is crucial for model evaluation and potential data augmentation strategies.

"""

# Assuming `image_files` contains all UTKFace image paths
ages = [int(os.path.basename(path).split('_')[0]) for path in image_files if path.split('_')[0].isdigit()]

plt.figure(figsize=(12, 5))
plt.hist(ages, bins=range(0, 100, 5), edgecolor='black', color='skyblue')
plt.title("Age Distribution in UTKFace Dataset")
plt.xlabel("Age")
plt.ylabel("Number of Samples")
plt.grid(True)
plt.show()

"""### Prediction Error Plot (Error by Age Group)

This scatter plot visualizes the prediction errors (Predicted Age âˆ’ Actual Age) against the actual ages of individuals in the validation set.

The horizontal dashed line represents zero error, where the predicted age perfectly matches the actual age. Points above the line indicate overestimation, while those below suggest underestimation.

**Key Observations:**
- The model tends to **overestimate age** for younger individuals (e.g., toddlers and teens).
- There is a slight **underestimation trend** in the higher age groups.
- The prediction spread narrows around the 25â€“40 age range, indicating higher accuracy for middle-aged individuals.

Such insights are useful for identifying model bias and guiding future improvements, like using age-balanced sampling or error-aware loss functions.
"""

actuals = []
predictions = []

# Evaluate on some validation samples
for img, actual_age in val_images[:200]:
    pred = model.predict(tf.expand_dims(img, 0), verbose=0)[0][0]
    actuals.append(actual_age)
    predictions.append(pred)

errors = np.array(predictions) - np.array(actuals)

plt.figure(figsize=(12, 5))
plt.scatter(actuals, errors, alpha=0.5, c='red')
plt.axhline(y=0, color='black', linestyle='--')
plt.title("Prediction Errors by Age")
plt.xlabel("Actual Age")
plt.ylabel("Prediction Error (Predicted - Actual)")
plt.grid(True)
plt.show()